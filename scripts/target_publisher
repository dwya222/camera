#!/usr/bin/env python3

import cv2
from dt_apriltags import Detector
import numpy as np
import numpy.linalg as L
import os
import pyrealsense2 as rs
from random import randint
from scipy.spatial.transform import Rotation

import rospy
from geometry_msgs.msg import Point
import rospkg

RGB_CAMERA_WIDTH = 1280
RGB_CAMERA_HEIGHT = 720
D_CAMERA_WIDTH = 640
D_CAMERA_HEIGHT = 480
TARGET_TAG_SIZE = 0.026

# Setting DEBUG to true shows camera view window
DEBUG = True

def main():
    rospy.init_node('target_publisher')
    target_topic = '/point_command'
    # Setup target tag position publisher
    target_point_pub = rospy.Publisher(target_topic, Point, queue_size=1)
    # Allocate point goal msg
    point_goal = Point()

    # Load calibration model (raise exception if unable)
    rospack = rospkg.RosPack()
    ee_control_path = rospack.get_path('end_effector_control')
    calibration_path = os.path.join(ee_control_path, 'config', 'calibration')
    try:
        A = np.load(os.path.join(calibration_path, 'A.npy'))
        b = np.load(os.path.join(calibration_path, 'b.npy'))
        # Setup calibrated point publisher
        cal_ee_point_pub = rospy.Publisher('/cal_ee_position', Point, queue_size=1)
    except FileNotFoundError as e:
        rospy.logerr(f"Calibration model files not found in dir {ee_control_path}. Unable to "
                     f"proceed without calibration (please calibrate). Re-raising exception...")
        raise e

    # Setup OpenCV for debugging
    cv2.namedWindow("Color", cv2.WINDOW_AUTOSIZE)
    cv2.namedWindow("Depth", cv2.WINDOW_AUTOSIZE)

    # Initialize RealSense
    cfg = rs.config()

    cfg.enable_stream(rs.stream.color, RGB_CAMERA_WIDTH, RGB_CAMERA_HEIGHT, rs.format.bgr8, 30)
    cfg.enable_stream(rs.stream.depth, D_CAMERA_WIDTH, D_CAMERA_HEIGHT, rs.format.z16, 30)

    pipeline = rs.pipeline()
    pipeline.start(cfg)

    profile = pipeline.get_active_profile()
    rgb_profile = rs.video_stream_profile(profile.get_stream(rs.stream.color))
    rgb_intrinsics = rgb_profile.get_intrinsics()

    FOCAL_X = rgb_intrinsics.fx
    FOCAL_Y = rgb_intrinsics.fy
    PRINCIPAL_X = rgb_intrinsics.ppx
    PRINCIPAL_Y = rgb_intrinsics.ppy

    # Setup AprilTags Detector
    target_detector = Detector(families='tagStandard41h12',
                               nthreads=1,
                               quad_decimate=1.0,
                               quad_sigma=0.0,
                               refine_edges=1,
                               decode_sharpening=0.25,
                               debug=0)
    # target_hmat = None
    target_vec = None

    # Let camera warm up for some frames
    for _ in range(30):
        pipeline.wait_for_frames()

    while not rospy.is_shutdown():
        frames = pipeline.wait_for_frames()
        color = frames.get_color_frame()
        depth = frames.get_depth_frame()
        if not color or not depth:
            continue

        # Convert images to np arrays
        depth_img = np.asanyarray(depth.get_data())
        color_img = np.asanyarray(color.get_data())

        # AprilTags only allows for grayscale, so convert here
        gray = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)

        camera_params = (FOCAL_X, FOCAL_Y, PRINCIPAL_X, PRINCIPAL_Y)

        target_tags = target_detector.detect(gray, True, camera_params, TARGET_TAG_SIZE)
        for tag in target_tags:
            # target_hmat = hmat(tag.pose_R, tag.pose_t)
            target_vec = np.append(tag.pose_t, 1)
            for idx in range(len(tag.corners)):
                cv2.line(color_img, tuple(tag.corners[idx-1, :].astype(int)),
                         tuple(tag.corners[idx, :].astype(int)), (0, 255, 0))
                draw_pose_axes(color_img, camera_params, TARGET_TAG_SIZE, tag.pose_R, tag.pose_t,
                               tag.center)

        if DEBUG:
            cv2.imshow("Color", color_img)
            #cv2.imshow("Depth", ctr_img)
            k = cv2.waitKey(1)

        # publish target point
        try:
            np_point = np.array([[target_vec[0]], [target_vec[1]], [target_vec[2]]])
            calibrated_np_point = A @ np_point + b
            point_goal.x = calibrated_np_point[0]
            point_goal.y = calibrated_np_point[1]
            point_goal.z = calibrated_np_point[2]
            target_point_pub.publish(point_goal)
        except TypeError as e:
            rospy.logwarn("TypeError caught. Camera likely unable to find target AprilTag, is it "
                          f"in view?. \nTraceback: {e}")

def pose_to_hmat(pose):
    # unused
    r = Rotation.from_quat([pose.orientation.x, pose.orientation.y, pose.orientation.z,
                            pose.orientation.w])
    r_mat = r.as_matrix()
    t = np.array([[pose.position.x], [pose.position.y], [pose.position.z]])
    return hmat(r_mat, t)

def hmat(R, t):
    # unused
    out = np.hstack((R, t))
    out = np.vstack((out, [0,0,0,1]))
    return out

def draw_pose_axes(overlay, camera_params, tag_size, pose_R, pose_t, center):
    fx, fy, cx, cy = camera_params
    K = np.array([fx, 0, cx, 0, fy, cy, 0, 0, 1]).reshape(3, 3)

    rvec, _ = cv2.Rodrigues(pose_R)
    tvec = pose_t

    dcoeffs = np.zeros(5)

    opoints = np.float32([[1,0,0],
                         [0,1,0],
                         [0,0,1]]).reshape(-1,3) * tag_size

    ipoints, _ = cv2.projectPoints(opoints, rvec, tvec, K, dcoeffs)
    ipoints = np.round(ipoints).astype(int)

    center = np.round(center).astype(int)
    center = tuple(center.ravel())

    cv2.line(overlay, center, tuple(ipoints[0].ravel()), (0,0,255), 2)
    cv2.line(overlay, center, tuple(ipoints[1].ravel()), (0,255,0), 2)
    cv2.line(overlay, center, tuple(ipoints[2].ravel()), (255,0,0), 2)


if __name__ == '__main__':
    main()
